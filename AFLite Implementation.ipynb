{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import string\n",
    "import sys\n",
    "import random\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-1] != 'winogrande_1.1':\n",
    "    os.chdir('/home/bssachde/Winogrande/winogrande_1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('train.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pd.DataFrame(data)\n",
    "S=D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>option1</th>\n",
       "      <th>option2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2</td>\n",
       "      <td>Kyle doesn't wear leg warmers to bed, while Lo...</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Logan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3ZG552ORAM2T6G7V1E3PMORI94N2VA-1</td>\n",
       "      <td>Studying economics was far easier for Megan th...</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Monica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-1</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-2</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   qID  \\\n",
       "0     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2   \n",
       "1     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1   \n",
       "2     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1   \n",
       "3     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2   \n",
       "4     3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2   \n",
       "...                                ...   \n",
       "9995  3ZG552ORAM2T6G7V1E3PMORI94N2VA-1   \n",
       "9996  3ZLW647WAN9OOW4J129JVRN8D4F32J-1   \n",
       "9997  3ZLW647WAN9OOW4J129JVRN8D4F32J-2   \n",
       "9998  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2   \n",
       "9999  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1   \n",
       "\n",
       "                                               sentence  option1 option2  \\\n",
       "0     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "1     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "2     He never comes to my home, but I always go to ...     home   house   \n",
       "3     He never comes to my home, but I always go to ...     home   house   \n",
       "4     Kyle doesn't wear leg warmers to bed, while Lo...     Kyle   Logan   \n",
       "...                                                 ...      ...     ...   \n",
       "9995  Studying economics was far easier for Megan th...    Megan  Monica   \n",
       "9996  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9997  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9998  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "9999  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "\n",
       "     answer  \n",
       "0         2  \n",
       "1         1  \n",
       "2         1  \n",
       "3         2  \n",
       "4         2  \n",
       "...     ...  \n",
       "9995      1  \n",
       "9996      1  \n",
       "9997      2  \n",
       "9998      2  \n",
       "9999      1  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 # Target Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load module for test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Load set of Linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Load non-Linear Models\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer libraries for fine tune embeddings\n",
    "from pytorch_transformers import BertPreTrainedModel, RobertaConfig, \\\n",
    "    ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP, RobertaModel\n",
    "from pytorch_transformers.modeling_roberta import RobertaClassificationHead\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is for pretraining\n",
    "# !git clone https://github.com/allenai/winogrande.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import os\n",
    "# # os.chdir(\"winogrande/\")\n",
    "# !export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "# !python \"scripts/run_experiment.py\" --model_type roberta_mc --model_name_or_path roberta-large --task_name winogrande --do_eval --do_lower_case --data_dir ./data  --max_seq_length 80  --per_gpu_eval_batch_size 4  --per_gpu_train_batch_size 16  --learning_rate 1e-5  --num_train_epochs 3  --output_dir ./output/models/  --do_train  --logging_steps 4752  --save_steps 4750  --seed 42  --data_cache_dir ./output/cache/  --warmup_pct 0.1  --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"models/pytorch_model.bin\"\n",
    "model_state_dict = torch.load(output_model_file) \n",
    "model = RobertaModel.from_pretrained('roberta-large',state_dict=model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = ['This framework generates embeddings for each input sentence',\n",
    "#     'Sentences are passed as a list of string.']\n",
    "# outputembeddings = model.get_output_embeddings()\n",
    "X = []\n",
    "len(S['sentence'])\n",
    "for sentence in S['sentence']:\n",
    "#     print(sentence)\n",
    "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    X.append(model(input_ids))#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while len(S) > n:\n",
    "#Dictionary to save the mdoel predictions for every individual elements.\n",
    "E = dict.fromkeys(S['qID'])\n",
    "EPrime = dict.fromkeys(S['sentence'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "## Train models\n",
    "# lm = LogisticRegression(random_state=0)\n",
    "# lm.fit(X_train, y_train)\n",
    "# rbf_svc = svm.SVC(kernel='rbf')\n",
    "# rbf_svc.fit(X_train,y_train)\n",
    "## Predictions\n",
    "# predictions = lm.predict(X_test)\n",
    "# predictions = rbf_svc.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
