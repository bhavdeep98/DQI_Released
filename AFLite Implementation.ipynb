{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import string\n",
    "import sys\n",
    "import random\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd().split('/')[-1] != 'winogrande_1.1':\n",
    "    os.chdir('/home/bssachde/Winogrande/winogrande_1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('train.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pd.DataFrame(data)\n",
    "S=D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>option1</th>\n",
       "      <th>option2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2</td>\n",
       "      <td>Kyle doesn't wear leg warmers to bed, while Lo...</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Logan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3ZG552ORAM2T6G7V1E3PMORI94N2VA-1</td>\n",
       "      <td>Studying economics was far easier for Megan th...</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Monica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-1</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-2</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   qID  \\\n",
       "0     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2   \n",
       "1     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1   \n",
       "2     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1   \n",
       "3     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2   \n",
       "4     3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2   \n",
       "...                                ...   \n",
       "9995  3ZG552ORAM2T6G7V1E3PMORI94N2VA-1   \n",
       "9996  3ZLW647WAN9OOW4J129JVRN8D4F32J-1   \n",
       "9997  3ZLW647WAN9OOW4J129JVRN8D4F32J-2   \n",
       "9998  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2   \n",
       "9999  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1   \n",
       "\n",
       "                                               sentence  option1 option2  \\\n",
       "0     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "1     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "2     He never comes to my home, but I always go to ...     home   house   \n",
       "3     He never comes to my home, but I always go to ...     home   house   \n",
       "4     Kyle doesn't wear leg warmers to bed, while Lo...     Kyle   Logan   \n",
       "...                                                 ...      ...     ...   \n",
       "9995  Studying economics was far easier for Megan th...    Megan  Monica   \n",
       "9996  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9997  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9998  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "9999  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "\n",
       "     answer  \n",
       "0         2  \n",
       "1         1  \n",
       "2         1  \n",
       "3         2  \n",
       "4         2  \n",
       "...     ...  \n",
       "9995      1  \n",
       "9996      1  \n",
       "9997      2  \n",
       "9998      2  \n",
       "9999      1  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The y label will be of the form [ 0 1 ] which implies the second option is the answer ####\n",
    "y = []\n",
    "for answer_index in range(0,len(S['answer'])):\n",
    "#     print(S['answer'][answer_index])\n",
    "    if S['answer'][answer_index]=='2':\n",
    "        y.append([0,1])\n",
    "#         y.append(S['option2'][answer_index])\n",
    "    else:\n",
    "        y.append([1,0])\n",
    "#         y.append(S['option1'][answer_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "### Verify the label format ###\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target Dataset size ##\n",
    "n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load module for test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Load set of Linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Load non-Linear Models\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer libraries for fine tune embeddings\n",
    "from pytorch_transformers import BertPreTrainedModel, RobertaConfig, \\\n",
    "    ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP, RobertaModel\n",
    "from pytorch_transformers.modeling_roberta import RobertaClassificationHead\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is for pretraining\n",
    "# !git clone https://github.com/allenai/winogrande.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.chdir(\"winogrande/\")\n",
    "# !export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "# !python \"scripts/run_experiment.py\" --model_type roberta_mc --model_name_or_path roberta-large --task_name winogrande --do_eval --do_lower_case --data_dir ./data  --max_seq_length 80  --per_gpu_eval_batch_size 4  --per_gpu_train_batch_size 16  --learning_rate 1e-5  --num_train_epochs 3  --output_dir ./output/models/  --do_train  --logging_steps 4752  --save_steps 4750  --seed 42  --data_cache_dir ./output/cache/  --warmup_pct 0.1  --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"models/pytorch_model.bin\"\n",
    "model_state_dict = torch.load(output_model_file) \n",
    "model = RobertaModel.from_pretrained('roberta-large',state_dict=model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.']\n",
    "# outputembeddings = model.get_output_embeddings()\n",
    "X = []\n",
    "# len(S['sentence'])\n",
    "for sentence in sentences:\n",
    "#     print(sentence)\n",
    "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    X.append(model(input_ids))#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2019,  0.7249,  0.3812,  ..., -0.0937,  0.5541, -0.4825]],\n",
      "       grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.2273,  0.7234,  0.4199,  ..., -0.1292,  0.5610, -0.4770]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "### The model basically returns the top layer embeddings and the pooled layer ###\n",
    "for element in X:\n",
    "    print(element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### We are using pickle to save the progress in a file ###\n",
    "import pickle\n",
    "\n",
    "# X_prime = []\n",
    "# ## Check if there was already some progress then continue from there otherwise just start from begining\n",
    "# if not os.path.isfile(\"start_pooled.data\"):\n",
    "#     start = 0\n",
    "# else:\n",
    "#     with open(\"start_pooled.data\",\"r\") as fileHandle:\n",
    "#         start = fileHandle.readline()\n",
    "#         # Scenario if file is there but nothing is in the file\n",
    "#         if start == '':\n",
    "#             start = 0\n",
    "# for index in range(int(start),len(S['sentence'])):\n",
    "# #     if index==78:\n",
    "# #         index=index+5\n",
    "#     if index%50==0:\n",
    "#         print(\"Saving the progress for embeddings\")\n",
    "#         with open('listfile_pooled.data', 'a+b') as filehandle:\n",
    "#             pickle.dump(X_prime, filehandle, pickle.HIGHEST_PROTOCOL)\n",
    "#         ## Reset the embeddings list X_prime and just keep appending the data in the file\n",
    "#         X_prime = []\n",
    "#         ## overwrite the index so far in seprate file\n",
    "#         with open(\"start_pooled.data\",\"w\") as fileHandle:\n",
    "#             fileHandle.write(str(index))\n",
    "#     print(index)\n",
    "#     input_ids = torch.tensor(tokenizer.encode(S['sentence'][index], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "#     X_prime.append(model(input_ids)[1][0])#, masked_lm_labels=input_ids)\n",
    "\n",
    "# ### We have to save one more time after the loop is over otherwise the last 50 value won't be saved just calculated ###    \n",
    "# print(\"Saving the progress for embeddings\")\n",
    "# with open('listfile_pooled.data', 'a+b') as filehandle:\n",
    "#     pickle.dump(X_prime, filehandle, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### Now we have to get the pooled embeddings for both the options ### \n",
    "\n",
    "# # y_emb_option_1 = []\n",
    "# y_emb_option_2 = []\n",
    "\n",
    "\n",
    "# ## region ## This is for mainting the position where the code was inturrupted due to any reason what so ever ##\n",
    "# if not os.path.isfile(\"start_y_pooled.data\"):\n",
    "#     start = 0\n",
    "# else:\n",
    "#     with open(\"start_y_pooled.data\",\"r\") as fileHandle:\n",
    "#         start = fileHandle.readline()\n",
    "#         # Scenario if file is there but nothing is in the file\n",
    "#         if start == '':\n",
    "#             start = 0\n",
    "# ## end region \n",
    "\n",
    "# # ## getting embedding for option 1\n",
    "# # for index in range(0,len(S['option1'])):\n",
    "# #     if index%50==0 and index!=0:\n",
    "# #         print(\"Saving the progress for embeddings\")\n",
    "# #         with open('y_label_pooled_option1.data', 'a+b') as filehandle:\n",
    "# #             pickle.dump(y_emb_option_1, filehandle, pickle.HIGHEST_PROTOCOL)\n",
    "# #         ## Reset the embeddings list X_prime and just keep appending the data in the file\n",
    "# #         y_emb_option_1 = []\n",
    "# #         ## overwrite the index so far in seprate file\n",
    "# #         with open(\"start_y_pooled.data\",\"w\") as fileHandle:\n",
    "# #             fileHandle.write(str(index))\n",
    "# #     print(index)\n",
    "# #     input_ids = torch.tensor(tokenizer.encode(S['option1'][index], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "# # #     print(input_ids)\n",
    "# #     output_ids = model(input_ids)[1][0]\n",
    "# #     y_emb_option_1.append(output_ids)#, masked_lm_labels=input_ids)\n",
    "    \n",
    "# # print(\"Saving the progress for embeddings\")\n",
    "# # with open('y_label_pooled_option1.data', 'a+b') as filehandle:\n",
    "# #     pickle.dump(y_emb_option_1, filehandle, pickle.HIGHEST_PROTOCOL)\n",
    "# # ## overwrite the index so far in seprate file\n",
    "# # with open(\"start_y_pooled.data\",\"w\") as fileHandle:\n",
    "# #     fileHandle.write(str(index))\n",
    "\n",
    "\n",
    "# ## getting embedding for option 2\n",
    "# for index in range(int(start),len(S['option2'])):\n",
    "#     if index%50==0 and index!=0:\n",
    "#         print(\"Saving the progress for embeddings\")\n",
    "#         with open('y_label_pooled_option2.data', 'a+b') as filehandle:\n",
    "#             pickle.dump(y_emb_option_2, filehandle, pickle.HIGHEST_PROTOCOL)\n",
    "#         ## Reset the embeddings list X_prime and just keep appending the data in the file\n",
    "#         y_emb_option_1 = []\n",
    "#         ## overwrite the index so far in seprate file\n",
    "#         with open(\"start_y_pooled.data\",\"w\") as fileHandle:\n",
    "#             fileHandle.write(str(index))\n",
    "#     print(index)\n",
    "#     input_ids = torch.tensor(tokenizer.encode(S['option2'][index], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "# #     print(input_ids)\n",
    "#     output_ids = model(input_ids)[1][0]\n",
    "#     y_emb_option_2.append(output_ids)#, masked_lm_labels=input_ids)\n",
    "    \n",
    "# print(\"Saving the progress for embeddings\")\n",
    "# with open('y_label_pooled_option2.data', 'a+b') as filehandle:\n",
    "#     pickle.dump(y_emb_option_2, filehandle, pickle.HIGHEST_PROTOCOL)\n",
    "# ## overwrite the index so far in seprate file\n",
    "# with open(\"start_y_pooled.data\",\"w\") as fileHandle:\n",
    "#     fileHandle.write(str(index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### verify the Embeddings for options ###\n",
    "# print(y_emb_option_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241175722"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n",
    "os.path.getsize('y_label_pooled_option2.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_option1 = []\n",
    "y_option2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listfile_pooled.data', mode='br') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            X.append(pickle.load(f))\n",
    "        except:\n",
    "            break\n",
    "with open('y_label_pooled_option1.data', mode='br') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            y_option1.append(pickle.load(f))\n",
    "        except:\n",
    "            break\n",
    "with open('y_label_pooled_option2.data', mode='br') as f:\n",
    "    while 1:\n",
    "        try:\n",
    "            y_option2.append(pickle.load(f))\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "### The final features look something like follows:\n",
    "### <Sentence embeddings> <Option 1> <Sentence embeddings> <Option 2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for sublist in X:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item.detach().numpy())\n",
    "\n",
    "X = flat_list[::]\n",
    "## make a copy for the Sentence embeddings \n",
    "X_copy = flat_list[::]            \n",
    "\n",
    "flat_list = []\n",
    "for sublist in y_option1:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item.detach().numpy())\n",
    "\n",
    "y_option1 = flat_list[::]\n",
    "\n",
    "flat_list = []\n",
    "for sublist in y_option2:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item.detach().numpy())\n",
    "\n",
    "y_option2 = flat_list[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "Ian volunteered to eat Dennis's menudo after already having a bowl because _ despised eating intestine.\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y_option2))\n",
    "print(S['sentence'][0])\n",
    "# X_prime = []\n",
    "# for element in X:\n",
    "#     X_prime.append(np.asarray(element[0][0]))\n",
    "X_prime = []\n",
    "for x1,y1,x2,y2 in zip(X,y_option1,X_copy,y_option2):\n",
    "#     print(len(x1))\n",
    "#     print(len(y1))\n",
    "#     print(len(x2))\n",
    "#     print(len(y2))\n",
    "    temp = [*x1,*y1,*x2,*y2]\n",
    "#     print(len(temp))\n",
    "    X_prime.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for element in X_prime:\n",
    "#     print(len(element))\n",
    "# print(y.shape)\n",
    "X_temp = np.asarray(X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_temp.shape\n",
    "y_temp = np.asarray(y)\n",
    "print(y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_prime = []\n",
    "# for element in y:\n",
    "#     y_prime.append(np.asarray(element[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for element in y_prime:\n",
    "#     print(element.shape)\n",
    "    \n",
    "# y_double_prime = S['answer'][:-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_double_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bssachde/.conda/envs/math_deomain2/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning:\n",
      "\n",
      "elementwise comparison failed; this will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "def find_index_of_array(list, array):\n",
    "    for i in range(len(list)):\n",
    "        if np.all(list[i]==array):\n",
    "            return i\n",
    "# while len(S) > n:\n",
    "#Dictionary to save the mdoel predictions for every individual elements.\n",
    "E = dict.fromkeys(S['qID'])\n",
    "EPrime = dict.fromkeys(S['sentence'])\n",
    "\n",
    "D = {}\n",
    "results = {}\n",
    "# print(D)\n",
    "m=10\n",
    "for i in range(0,m):\n",
    "    ## 90 percent of the data is in the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.90, random_state=42)\n",
    "    \n",
    "    ## Train models\n",
    "    ### Logistic Regression\n",
    "    lm = LabelPowerset(LogisticRegression(random_state=0,max_iter=1000))\n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    ### SVM\n",
    "    rbf_svc = LabelPowerset(svm.SVC(kernel='rbf'))\n",
    "    rbf_svc.fit(X_train,y_train)\n",
    "    \n",
    "    # Predictions\n",
    "#     for element in X_test:\n",
    "\n",
    "    predictions = lm.predict(X_test)\n",
    "    predictions_svm = rbf_svc.predict(X_test)\n",
    "#     X_test_dict = {}\n",
    "    for i in range(0,len(X_test)):\n",
    "#         print(X_test[i])\n",
    "        index = find_index_of_array(X,X_test[i])\n",
    "#         print(index)\n",
    "        if index not in D.keys():\n",
    "            D[index] = [predictions[i],predictions_svm[i]]\n",
    "        else:\n",
    "            D[index].append(predictions[i])\n",
    "            D[index].append(predictions_svm[i])\n",
    "        results[index] = y_test[i]\n",
    "        \n",
    "        \n",
    "#predictibility score\n",
    "P = {}\n",
    "for key,value in D.items():\n",
    "#     print(value)\n",
    "#     print(results[key])\n",
    "#     print(value.count(results[key])/len(value))\n",
    "    P[key] = value.count(results[key])/len(value)\n",
    "# print(P)\n",
    "#     print(predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
