{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import string\n",
    "import sys\n",
    "import random\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-1] != 'winogrande_1.1':\n",
    "    os.chdir('/home/bssachde/Winogrande/winogrande_1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('train.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=pd.DataFrame(data)\n",
    "S=D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>sentence</th>\n",
       "      <th>option1</th>\n",
       "      <th>option2</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1</td>\n",
       "      <td>Ian volunteered to eat Dennis's menudo after a...</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2</td>\n",
       "      <td>He never comes to my home, but I always go to ...</td>\n",
       "      <td>home</td>\n",
       "      <td>house</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2</td>\n",
       "      <td>Kyle doesn't wear leg warmers to bed, while Lo...</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Logan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3ZG552ORAM2T6G7V1E3PMORI94N2VA-1</td>\n",
       "      <td>Studying economics was far easier for Megan th...</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Monica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-1</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3ZLW647WAN9OOW4J129JVRN8D4F32J-2</td>\n",
       "      <td>Lorelei took the carnation out of the jar and ...</td>\n",
       "      <td>jar</td>\n",
       "      <td>vase</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1</td>\n",
       "      <td>Felicia only likes dogs for pets while Laura o...</td>\n",
       "      <td>Felicia</td>\n",
       "      <td>Laura</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   qID  \\\n",
       "0     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-2   \n",
       "1     3QHITW7OYO7Q6B6ISU2UMJB84ZLAQE-1   \n",
       "2     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-1   \n",
       "3     3XWUWJ18TLO2DDRXF83QWLKRJ29UU4-2   \n",
       "4     3D5G8J4N5CI2K40F4RZLF9OG2CKVTH-2   \n",
       "...                                ...   \n",
       "9995  3ZG552ORAM2T6G7V1E3PMORI94N2VA-1   \n",
       "9996  3ZLW647WAN9OOW4J129JVRN8D4F32J-1   \n",
       "9997  3ZLW647WAN9OOW4J129JVRN8D4F32J-2   \n",
       "9998  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-2   \n",
       "9999  3KA7IJSNW63AP9AVYVN1HP54HO0BP5-1   \n",
       "\n",
       "                                               sentence  option1 option2  \\\n",
       "0     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "1     Ian volunteered to eat Dennis's menudo after a...      Ian  Dennis   \n",
       "2     He never comes to my home, but I always go to ...     home   house   \n",
       "3     He never comes to my home, but I always go to ...     home   house   \n",
       "4     Kyle doesn't wear leg warmers to bed, while Lo...     Kyle   Logan   \n",
       "...                                                 ...      ...     ...   \n",
       "9995  Studying economics was far easier for Megan th...    Megan  Monica   \n",
       "9996  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9997  Lorelei took the carnation out of the jar and ...      jar    vase   \n",
       "9998  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "9999  Felicia only likes dogs for pets while Laura o...  Felicia   Laura   \n",
       "\n",
       "     answer  \n",
       "0         2  \n",
       "1         1  \n",
       "2         1  \n",
       "3         2  \n",
       "4         2  \n",
       "...     ...  \n",
       "9995      1  \n",
       "9996      1  \n",
       "9997      2  \n",
       "9998      2  \n",
       "9999      1  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000 # Target Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load module for test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Load set of Linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Load non-Linear Models\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer libraries for fine tune embeddings\n",
    "from pytorch_transformers import BertPreTrainedModel, RobertaConfig, \\\n",
    "    ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP, RobertaModel\n",
    "from pytorch_transformers.modeling_roberta import RobertaClassificationHead\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is for pretraining\n",
    "# !git clone https://github.com/allenai/winogrande.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import os\n",
    "# # os.chdir(\"winogrande/\")\n",
    "# !export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
    "# !python \"scripts/run_experiment.py\" --model_type roberta_mc --model_name_or_path roberta-large --task_name winogrande --do_eval --do_lower_case --data_dir ./data  --max_seq_length 80  --per_gpu_eval_batch_size 4  --per_gpu_train_batch_size 16  --learning_rate 1e-5  --num_train_epochs 3  --output_dir ./output/models/  --do_train  --logging_steps 4752  --save_steps 4750  --seed 42  --data_cache_dir ./output/cache/  --warmup_pct 0.1  --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"models/pytorch_model.bin\"\n",
    "model_state_dict = torch.load(output_model_file) \n",
    "model = RobertaModel.from_pretrained('roberta-large',state_dict=model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sentences = ['This framework generates embeddings for each input sentence',\n",
    "# #     'Sentences are passed as a list of string.']\n",
    "# # outputembeddings = model.get_output_embeddings()\n",
    "# X = []\n",
    "# len(S['sentence'])\n",
    "# for sentence in S['sentence']:\n",
    "# #     print(sentence)\n",
    "#     input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "#     X.append(model(input_ids)[0])#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# X_prime = []\n",
    "# ## Check if there was already some progress then continue from there otherwise just start from begining\n",
    "# if not os.path.isfile(\"start.data\"):\n",
    "#     start = 0\n",
    "# else:\n",
    "#     with open(\"start.data\",\"r\") as fileHandle:\n",
    "#         start = fileHandle.readline()\n",
    "#         # Scenario if file is there but nothing is in the file\n",
    "#         if start == '':\n",
    "#             start = 0\n",
    "# for index in range(int(start),len(S['sentence'])):\n",
    "# #     if index==78:\n",
    "# #         index=index+5\n",
    "#     if index%50==0:\n",
    "#         print(\"Saving the progress for embeddings\")\n",
    "#         with open('listfile.data', 'ab') as filehandle:\n",
    "#             pickle.dump(X_prime, filehandle)\n",
    "#         ## Reset the embeddings list X_prime and just keep appending the data in the file\n",
    "#         X_prime = []\n",
    "#         ## overwrite the index so far in seprate file\n",
    "#         with open(\"start.data\",\"w\") as fileHandle:\n",
    "#             fileHandle.write(str(index))\n",
    "#     print(index)\n",
    "#     input_ids = torch.tensor(tokenizer.encode(S['sentence'][index], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "#     X_prime.append(model(input_ids)[0])#, masked_lm_labels=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971901704"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n",
    "os.path.getsize('listfile.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xc7'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-de577071f4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# with open('listfile.data', 'rb') as filehandle:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/xrn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilehandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\xc7'."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "# with open('listfile.data', 'rb') as filehandle:\n",
    "with open('data/xrn', 'rb') as filehandle:\n",
    "    X = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
      "1\n",
      "0.5\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1\n",
      "0.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "1\n",
      "0.5\n",
      "[1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
      "1\n",
      "0.5\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "1\n",
      "0.5\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1\n",
      "0.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1\n",
      "0.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1\n",
      "0.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "1\n",
      "0.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
      "1\n",
      "0.5\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "1\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "2\n",
      "1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "def find_index_of_array(list, array):\n",
    "    for i in range(len(list)):\n",
    "        if np.all(list[i]==array):\n",
    "            return i\n",
    "# while len(S) > n:\n",
    "#Dictionary to save the mdoel predictions for every individual elements.\n",
    "E = dict.fromkeys(S['qID'])\n",
    "EPrime = dict.fromkeys(S['sentence'])\n",
    "\n",
    "D = {}\n",
    "results = {}\n",
    "# print(D)\n",
    "m=10\n",
    "for i in range(0,m):\n",
    "    ## 90 percent of the data is in the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.90, random_state=42)\n",
    "    \n",
    "    ## Train models\n",
    "    ### Logistic Regression\n",
    "    lm = LogisticRegression(random_state=0)\n",
    "    lm.fit(X_train, y_train)\n",
    "    \n",
    "    ### SVM\n",
    "    rbf_svc = svm.SVC(kernel='rbf')\n",
    "    rbf_svc.fit(X_train,y_train)\n",
    "    \n",
    "    # Predictions\n",
    "#     for element in X_test:\n",
    "\n",
    "    predictions = lm.predict(X_test)\n",
    "    predictions_svm = rbf_svc.predict(X_test)\n",
    "#     X_test_dict = {}\n",
    "    for i in range(0,len(X_test)):\n",
    "#         print(X_test[i])\n",
    "        index = find_index_of_array(X,X_test[i])\n",
    "#         print(index)\n",
    "        if index not in D.keys():\n",
    "            D[index] = [predictions[i],predictions_svm[i]]\n",
    "        else:\n",
    "            D[index].append(predictions[i])\n",
    "            D[index].append(predictions_svm[i])\n",
    "        results[index] = y_test[i]\n",
    "        \n",
    "#predictibility score\n",
    "P = {}\n",
    "for key,value in D.items():\n",
    "    print(value)\n",
    "    print(results[key])\n",
    "    print(value.count(results[key])/len(value))\n",
    "    P[key] = value.count(results[key])/len(value)\n",
    "# print(P)\n",
    "#     print(predictions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
